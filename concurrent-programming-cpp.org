#+TITLE: C++ concurrent programming notes based on [[https://www.youtube.com/playlist?list=PL5jc9xFGsL8E12so1wlMS0r0hTQoJL74M][Bo's videos]]

** Concurrent programming models
1) Multi-processing
   - 1 thread / process
   - Threads communicate through /Interprocess communication/ channels e.g. files, types, message queues.
2) Multi-threading
   - >= 2 threads / process
   - Threads communicate through /shared memory/.
   - Pros
     * Thread faster to start (considered /light-weight process/).
     * Thread has low overhead (process needs extra protection to avoid over-stepping).
     * Communicating through shared memory faster than interprocess communication.
     * Overall, multi-threading provides better performance than multi-processing.
   - Cons
     * Difficult to implement (have to deal with thread specific issues).
     * Can't run on distributed systems; multi-processing on the other hand can be easily distributed on such systems and therefore, run concurrently.
       * Main reason for this is that shared memory blocks concurrent distribution

In practice, within the same program, one can expect to see a mixture of both
models i.e. some processes are single-threaded (Multi-processing model) and others
are multi-threaded (Multi-threading model).

In these notes, we'll mainly talk about the Multi-threading model.

** Getting started example

#+BEGIN_SRC C++ :exports both
#include <iostream>
#include <thread>

void f1() {
    std::cout << "message" << std::endl;
}
int main() {
    f1();
    return 0;
}
#+END_SRC

#+RESULTS:
: message

This program is not multi-threaded (only 1 thread running). 
Let's make this program multi-threaded:

#+BEGIN_SRC C++ :exports both
#include <iostream>
#include <thread>

void f1() {
    std::cout << "message" << std::endl;
}
int main() {
    std::thread t1(f1); // t1 thread (child of main thread) starts running
    t1.join();          // main thread waits for t1 to finish
    return 0;
}
#+END_SRC

#+RESULTS:
: message

Suppose t1 is long running and main thread doesn't want to wait:

#+BEGIN_SRC C++ :exports both
#include <iostream>
#include <thread>

void f1() {
    std::cout << "message" << std::endl;
}
int main() {
    std::thread t1(f1); // t1 thread (child of main thread) starts running
    t1.detach();        // t1 runs freely on its own (daemon process).
    return 0;
}
#+END_SRC

#+RESULTS:

Before getting to the result, note that detatch causes a daemon process to be
created. This means that when t1 is finished, since it's not connected to the
main thread, the C++ runtime library will reclaim the resource. Note however that
sometimes daemon process keep running until the machine is shut down.

Back to the result. We can see the nothing is printed. This is because the main thread
ran so quickly that it finished before t1 could print its message.

To avoid this un-determinism between two independent threads, we can add synchronization (later).

Some points:
- main() and main thread /owns/ f1() and t1 thread.
- calling detach however => main thread and t1 thread independent despite of owner or parent-child relationship
- typically, the owner should outlive its children.
- we can join and detach threads only once
  - => can not call join after detach; once detached, always detached.
  - can check if joinable though: t1.joibable
    
** Thread management
Our last example was:

#+BEGIN_SRC C++ :exports both
#include <iostream>
#include <thread>

void f1() {
    std::cout << "message" << std::endl;
}
int main() {
    std::thread t1(f1); 
    t1.detach();        // or t1.join()
    return 0;
}
#+END_SRC

Note that we have to make a decision to either join or detach the thread after
its created (and hence starts running). The decision has to be made before the thread
object goes out of scope.

Let's look at an example:

#+BEGIN_SRC C++ :exports both
#include <iostream>
#include <thread>

void f1() {
    std::cout << "f1" << std::endl;
}
int main() {
    std::thread t1(f1);
    // main thread  work while t1 is running
    try {
        for (int i = 0; i < 10; ++i)
            std::cout << "main: " << i << std::endl;
    } catch (...) {
        t1.join();
        throw; // rethrow the exception: hopefully someone else will catch and
               // handle it
    }
    t1.join(); // wait for t1 to finish
    return 0;
}
#+END_SRC

#+RESULTS:
| main: | 0 |
| main: | 1 |
| main: | 2 |
| main: | 3 |
| main: | 4 |
| main: | 5 |
| main: | 6 |
| main: | 7 |
| main: | 8 |
| main: | 9 |
| f1    |   |

Note that:
- we had to use try/catch for main thread's work because if we don't do that and then if the work throws an exception, t1 will go out of scope before being joined or detached.
- an alternative of try/catch here to ensure t1 is joined is wrapping the work in a class and use RAII

We saw that threads can be instanitated and hence associated with functions. In general,
threads can be associated with any [[http://en.cppreference.com/w/cpp/concept/Callable][callable]] object. Let's take a look at an example
where the callable object is a Functor class:

#+BEGIN_SRC C++ :exports both
#include <iostream>
#include <string>
#include <thread>

class Fctor {
  public:
    void operator()(const std::string& msg) {
        std::cout << "t1: " << msg << std::endl;
    }
};

int main() {
    const std::string s = "Answer to life is 42";
    std::thread t1((Fctor()), s);
    try {
        for (int i = 0; i < 10; ++i)
            std::cout << "main: " << s << std::endl;
    } catch (...) {
        t1.join();
        throw;
    }
    t1.join();
    return 0;
}
#+END_SRC

#+RESULTS:
| main: | Answer | to | life | is | 42 |
| main: | Answer | to | life | is | 42 |
| main: | Answer | to | life | is | 42 |
| main: | Answer | to | life | is | 42 |
| main: | Answer | to | life | is | 42 |
| main: | Answer | to | life | is | 42 |
| main: | Answer | to | life | is | 42 |
| main: | Answer | to | life | is | 42 |
| main: | Answer | to | life | is | 42 |
| main: | Answer | to | life | is | 42 |
| t1:   | Answer | to | life | is | 42 |

Note that even though Fctor argument is pass-by-reference, the parameter is passed
by value. This is because parameter to the thread is always passed by value. If
passing by reference is really needed, use std::ref to wrap the callsite argument.
Another option is to pass a pointer.

Also note that ideally, threads should share minimum memory to avoid data races.
So in the earlier example, if /s/ is not used in the main thread, we can use std::move
at the thread creation callsite to change the ownership of /s/ from the main thread to
t1. This is both safe and efficient. In C++, there are objects that can not be copied
but can be moved. An example is is the thread object itself i.e. std::thread t2 = t1
won't work but std::thread t2 = std::move(t1) will; it will move the ownership of t1 to
t2; t1 would then become empty.

Each thread also has a unique (?) identification number associated with it. To get that
numer, we can use std::this_thread::get_id() which will print current thread's id. To print
a specific thread's id, we can use t1.get_id().
** Data races and Mutex
Let's take an example:
#+BEGIN_SRC C++ :exports both
#include <iostream>
#include <thread>

void f1() {
    for (int i = 0; i > -10; --i)
        std::cout << "f1: " << i << std::endl;
}
int main() {
    std::thread t1(f1);
    for (int i = 0; i < 10; ++i)
        std::cout << "main: " << i << std::endl;
    t1.join();
    return 0;
}
#+END_SRC

#+RESULTS:
main: 0
f1: main: 1
0
f1: -1
f1: -2
f1: -3
f1: main: -42

f1: main: -53

f1: main: -64

f1: main: -75

f1: main: -86

f1: main: -97

main: 8
main: 9

The reason we get this garbled output is that there are two threads running
and writing to cout (std output) at the same time. In other words, both threads
are racing for a common resource, cout. This results in a race condition which means
the outcome of the program depends on the relative execution order of one or more threads.
This by defintion is un-determinstic.

One way to solve to race condition is to use mutex which synchronizes the access
of the common resource:

#+BEGIN_SRC C++ :exports both
#include <iostream>
#include <mutex>
#include <string>
#include <thread>

std::mutex mu;
void shared_print(const std::string& msg, const int id) {
    mu.lock();
    std::cout << msg << id << std::endl;
    mu.unlock();
}
void f1() {
    for (int i = 0; i > -10; --i)
        shared_print("f1: ", i);
}
int main() {
    std::thread t1(f1);
    for (int i = 0; i < 10; ++i)
        shared_print("main: ", i);
    t1.join();
    return 0;
}
#+END_SRC

#+RESULTS:
main: 0
main: 1
f1: 0
main: 2
f1: -1
main: 3
f1: -2
main: 4
f1: -3
main: 5
f1: -4
main: 6
f1: -5
main: 7
f1: -6
main: 8
f1: -7
main: 9
f1: -8
f1: -9

Now we can see that only both threads queue up and wait for each other before executing.
This is achieved using lock and unlock mechanism of the shared_print resource.

There is a problem with the above code though. If the shared_print cout code throws
an exception, the mutex will remain locked throughout the program. To fix this issue:

#+BEGIN_SRC C++ :exports both
#include <iostream>
#include <mutex>
#include <string>
#include <thread>

std::mutex mu;
void shared_print(const std::string& msg, const int id) {
    std::lock_guard<std::mutex> guard(mu); // RAII           
    std::cout << msg << id << std::endl;
}
void f1() {
    for (int i = 0; i > -10; --i)
        shared_print("f1: ", i);
}
int main() {
    std::thread t1(f1);
    for (int i = 0; i < 10; ++i)
        shared_print("main: ", i);
    t1.join();
    return 0;
}
#+END_SRC

#+RESULTS:
main: 0
f1: 0
main: 1
f1: -1
main: 2
f1: -2
main: 3
f1: -3
main: 4
f1: -4
main: 5
f1: -5
main: 6
f1: -6
main: 7
f1: -7
main: 8
f1: -8
main: 9
f1: -9

Here, RAII implies that once guard is destructed or goes out of scope, the destructor
automatically unlocks the mutex, mu.

Another problem with this example is that since cout is a global variable/resource, someone
else can access cout without going through shared_print.

Although cout is a global stream and it's hard to fully bind it to a mutex, other
things can be bounded:

#+BEGIN_SRC C++ :exports both
class LogFile {
  public:
    LogFile() {
        f.open("log.txt");
    }
    ~LogFile() {
        f.close();
    }
    void shared_print(const std::string& msg, const int id) {
        std::lock_guard<std::mutex> locker(m_mutex);
        f << "From " << msg << ": " << id << std::endl;
    }

  private:
    std::mutex m_mutex;
    std::ofstream f;
};

void f1(LogFile& log) {
    for (int i = 0; i < 100; ++i)
        log.shared_print("f1: ", i);
}

int main() {
    LogFile log;
    std::thread t1(f1, std::ref(log));
    return 0;
}
#+END_SRC

Now, we can only access the resource =f= via mutex. Note that it's a bad idea 
to expose this resource e.g. using a getter since the clients can then use it without
going through the mutex.

Now let's assume that we have avoided leaking the resource by abstracting in a class, 
does it guarentee that our program is thread-safe i.e. there is no race condition?

Let's look at a STL example:

#+BEGIN_SRC C++ :exports both
class Stack {
public:
  void pop();
  int top();
private:
  int* _data;
  std::mutex _mu;
};

void f1(Stack& st) {
  int v = st.top();
  st.pop();
  process(v);
}
#+END_SRC

Assume that pop() and top() access _data through the mutex. This code is not thread-safe even though we have protechted our resource (_data) using
a mutex. The reason is that 2 threads can call f1, which calls st.pop() and get the same
stack value. The reason is that although we have used mutex to synchronize data access,
the interface is inherently not thread-safe i.e. top() will return the same value
if called twice. One possible solution is to combine top() and pop() athlought it then
breaks the "one function should do one thing only" principle.

Note that although combining the two functions to something like int pop() would make
the program thread safe, it would still not be exception safe because if one thread calls
pop() and there is an exception thrown, the lock will remain locked until the end of the
program. This is why C++ STL doesn't return a value in std::stack pop()'s implementation.

** Deadlock

Mutex is a lock which provieds locking mechanism to threads. Now we have 2 mutexes as well.
That means that the resource can be accessed only when both mutexes are in an
unlocked state (note that locked and unlocked are the only two states for mutexes).

However, using more than one mutex can sometimes lead to /Deadlock/:

#+BEGIN_SRC C++ :exports both
#include <iostream>
#include <mutex>
#include <string>
#include <thread>

std::mutex mu;
std::mutex mu2;
void shared_print(const std::string& msg, const int id) {
    std::lock_guard<std::mutex> guard(mu); // RAII           
    std::lock_guard<std::mutex> guard2(mu2); // RAII           
    std::cout << msg << id << std::endl;
}
void shared_print2(const std::string& msg, const int id) {
    std::lock_guard<std::mutex> guard2(mu2); // RAII       
    std::lock_guard<std::mutex> guard(mu); // RAII               
    std::cout << msg << id << std::endl;
}
void f1() {
    for (int i = 0; i > -100; --i)
        shared_print2("f1: ", i);
}
int main() {
    std::thread t1(f1);
    for (int i = 0; i < 100; ++i)
        shared_print("main: ", i);
    t1.join();
    return 0;
}
#+END_SRC

#+RESULTS:
| main: |  0 |
| main: |  1 |
| main: |  2 |
| main: |  3 |
| main: |  4 |
| main: |  5 |
| main: |  6 |
| main: |  7 |
| main: |  8 |
| main: |  9 |

Notice that the program got stuck while printing and we had to C-c to terminate
the program. This happened because in =shared_print=, we locked =mu= and then =mu2=
and vice versa in =shared_print2=. Since both of the functions are associated with
threads that are running at the same time, this means that there was an instance e.g.
=shared_print= locked =mu= but before locking =mu2=, =shared_print2= locked it. Now
=shared_print= has to wait before =shared_print2= unlock it but =shared_print2= itself
locked =mu2= and =shared_print= locked =mu= before it could lock =mu= so =shared_print2=
is also waiting for =shared_print=. Now both functions are waiting for each other and 
therefore, we are in a deadlock situtation.

One possible solution is to use the same order of mutex locking in both functions.

C++ standard library has provided a better solution =std::lock= which can lock
arbitrary number of mutexes with deadlock avoiding mechanisms on top:

#+BEGIN_SRC C++ :exports both
std::lock(mu, mu2);
std::lock_guard<std::mutex> locker(mu, std::adopt_lock);
std::lock_guard<std::mutex> locker2(mu2, std::adopt_lock);
#+END_SRC

=std::adopt_lock= tells the locker that the mutex is already locked and all you (locker)
needs to do is to adopt the ownership of the mutex, so that when you go out of scope,
remember to unlock the mutex.

Other solutions to avoid deadlocks:
- Consider if you really need two lockers at the same time, else prefer locking single mutex at a time:
#+BEGIN_SRC C++ :exports both
{
std::lock_guard<std::mutex> locker(mu);
// do work
}
{
std::lock_guard<std::mutex> locker2(mu2);
// do work
}
#+END_SRC
- Avoid locking a mutex and then calling a user provided function

Lock granularity:
- Fine-grained lock: protects small amount of data
- Coarse-grained lock: protects large amount of data

** Unique_lock and lazy initialization
We can use =unique_lock= instead of =lock_guard= as follows:
#+BEGIN_SRC C++ :exports both
void shared_print(const std::string& id, const int val) {
    // std::lock_guard<std::mutex> locker(mu);
    // std::unique_lock<std::mutex> locker(mu);
    std::unique_lock<std::mutex> locker(mu, std::defer_lock);

    // do something else

    locker.lock();
    // use resource (which needed lock protection)
    locker.unlock();

    // lock again
    locker.lock();

    // can move but not copy
    std::unique_lock<std::mutex> locker2 = std::move(lock);

    // rest of the code
}
#+END_SRC

As we can see, =unique_lock= is more flexible in terms of when we can lock
and unlock. It can also allow multiple locks and unlocks. The downside of using
it over =lock_guard= is performance since it's more heavy weight.

Let's look at another example using lazy initialization:

#+BEGIN_SRC C++ :exports both
void shared_print(const std::string& id, const int val) {
    if (!f.is_open()) {
        f.open("log.txt"); // only open file once
                           // lazy initialization
                           // initialization upon first use idiom
    }
    std::unique_lock<std::mutex> locker(mu);
    f << "some string" << std::endl;
    locker.unlock();
}
#+END_SRC

Here, we are protecting by locking the printing to =f= but opening =f= is not protected
so multiple threads can open the file at the same time which is undesirable.
To fix this issue, we can move the =locker= up so that it protects opening =f= too
but that's not right since we open the file once while printing is done everytime the function
calls.

So one solution maybe to use another mutex =mu_open=:

#+BEGIN_SRC C++ :exports both
void shared_print(const std::string& id, const int val) {
    if (!f.is_open()) {
        std::unqiue_lock<std::mutex> locker2(mu_open);
        f.open("log.txt"); 
    }
    std::unique_lock<std::mutex> locker(mu);
    f << "some string" << std::endl;
    locker.unlock();
}
#+END_SRC

This program is still not thread safe since since =!f.is_open()= is
not protected. Let's do that:

#+BEGIN_SRC C++ :exports both
void shared_print(const std::string& id, const int val) {
    {
        std::unqiue_lock<std::mutex> locker2(mu_open);
        if (!f.is_open()) {
            f.open("log.txt");
        }
    }
    std::unique_lock<std::mutex> locker(mu);
    f << "some string" << std::endl;
    locker.unlock();
}
#+END_SRC

This program is now thread-safe but inefficient since every thread will do the locking
and then checking if file is open. C++ provides a better way in =std::once_flag flag=
which would also eliminate the need for an extra mutex for one-time checking:

#+BEGIN_SRC C++ :exports both
void shared_print(const std::string& id, const int val) {
    // file will be opened once by one (first) thread
    std::call_once(flag, [&](){f.open("log.txt");});

    std::unique_lock<std::mutex> locker(mu);
    f << "some string" << std::endl;
    locker.unlock();
}
#+END_SRC

** Condition variables


